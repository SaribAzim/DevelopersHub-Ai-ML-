# -*- coding: utf-8 -*-
"""Task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FMibjRjmv71T3lc1nuPithmWEQIKXt9r
"""

!pip install tensorflow

# ===========================
# CNN for Breast Cancer Histopathology
# ===========================

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam


# ===========================
# Step 1: Dataset & Preprocessing
# ===========================

# Assuming dataset structure:
# dataset/
#    benign/
#    malignant/

data_dir = '/content/drive/MyDrive/Dataset_BUSI_with_GT'  # no zip needed

img_size = (128, 128)
batch_size = 32

# Image data generator for training and validation
datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_gen = datagen.flow_from_directory(
    data_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    subset='training',
    shuffle=True
)

val_gen = datagen.flow_from_directory(
    data_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    subset='validation',
    shuffle=False
)

# ===========================
# Step 2: Build Simple CNN
# ===========================

cnn_model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),
    MaxPooling2D((2,2)),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D((2,2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
cnn_model.summary()

# ===========================
# Step 3: Train the CNN
# ===========================

history = cnn_model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10
)

# ===========================
# Step 4: Evaluate the Model
# ===========================

plt.figure(figsize=(12,5))

# Plot accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

# ===========================
# Step 5 (Bonus): Transfer Learning with VGG16
# ===========================

vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(128,128,3))
vgg_base.trainable = False  # freeze pre-trained layers

transfer_model = Sequential([
    vgg_base,
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

transfer_model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])
transfer_model.summary()

history_transfer = transfer_model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10
)

cnn_model.save('my_cnn_model.h5')